# Introduction
* A good introduction on MCMC (chinese version) https://www.cnblogs.com/xbinworld/p/4266146.html
* Steps on using gibbs sampling: http://www.mit.edu/~ilkery/papers/GibbsSampling.pdf

# MCMC
* Tianqi chen HMC : https://arxiv.org/pdf/1402.4102.pdf
* A Complete Recipe for Stochastic Gradient MCMC: https://arxiv.org/pdf/1506.04696.pdf
* Bayesian Learning via Stochastic Gradient Langevin Dynamics: https://www.ics.uci.edu/~welling/publications/papers/stoclangevin_v6.pdf
* Hamiltonian monte carlo https://arxiv.org/pdf/1701.02434.pdf
* Hamiltonian MC video: https://www.youtube.com/watch?v=VnNdhsm0rJQ
* Hamiltonian MC: https://www.youtube.com/watch?v=pHsuIaPbNbY
* Neal, R.M. Bayesian learning
via stochastic dynamics. In
NIPS 1993. https://pdfs.semanticscholar.org/d275/cf94e620bf5b3776bba8a88acccdcfcd9a19.pdf
* Neal, R.M. Bayesian learning
for neural networks. PhD
thesis https://www.cs.toronto.edu/~radford/ftp/thesis.pdf
* Ghahramani, Z. (2015) https://www.repository.cam.ac.uk/bitstream/handle/1810/248538/Ghahramani%202015%20Nature.pdf
